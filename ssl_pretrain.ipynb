{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdI_mmxYsKvF",
   "metadata": {
    "executionInfo": {
     "elapsed": 5906,
     "status": "ok",
     "timestamp": 1698593571584,
     "user": {
      "displayName": "申牧義",
      "userId": "07372378923452571676"
     },
     "user_tz": -480
    },
    "id": "bdI_mmxYsKvF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model import *\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from Myloader import *\n",
    "import time\n",
    "import torchvision.models as models\n",
    "from torchmetrics.classification import MultilabelAveragePrecision\n",
    "from ssl_encoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "JbVO76fMsN6z",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1698593663020,
     "user": {
      "displayName": "申牧義",
      "userId": "07372378923452571676"
     },
     "user_tz": -480
    },
    "id": "JbVO76fMsN6z"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    test_running_loss = 0.0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        record_target_label = torch.zeros(1, 19).to(device)\n",
    "        record_predict_label = torch.zeros(1, 19).to(device)\n",
    "        for (test_imgs, test_labels, test_dicoms) in val_loader:\n",
    "            test_imgs = test_imgs.to(device)\n",
    "            test_labels = test_labels.to(device)\n",
    "            test_labels = test_labels.squeeze(-1)\n",
    "\n",
    "            test_output = model(test_imgs)\n",
    "            loss = criterion(test_output, test_labels)\n",
    "\n",
    "            test_running_loss += loss.item() * test_imgs.size(0)\n",
    "            test_total += test_imgs.size(0)\n",
    "\n",
    "            record_target_label = torch.cat((record_target_label, test_labels), 0)\n",
    "            record_predict_label = torch.cat((record_predict_label, test_output), 0)\n",
    "\n",
    "\n",
    "        record_target_label = record_target_label[1::]\n",
    "        record_predict_label = record_predict_label[1::]\n",
    "\n",
    "        metric = MultilabelAveragePrecision(num_labels=19, average=\"macro\", thresholds=None)\n",
    "        mAP = metric(record_predict_label, record_target_label.to(torch.int32))\n",
    "\n",
    "    return mAP, test_running_loss, test_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98IxbEK7snTT",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1698593829205,
     "user": {
      "displayName": "申牧義",
      "userId": "07372378923452571676"
     },
     "user_tz": -480
    },
    "id": "98IxbEK7snTT"
   },
   "outputs": [],
   "source": [
    "# set_seed(123)\n",
    "#     weight_dir = \"\"\n",
    "#     if not os.path.exists(weight_dir):\n",
    "#         os.makedirs(weight_dir)\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "num_classes = 19\n",
    "\n",
    "weight_path = \"weights/\"\n",
    "\n",
    "train_path = \"data/MICCAI_long_tail_train.tfrecords\"\n",
    "train_index = \"data/MICCAI_long_tail_train.tfindex\"\n",
    "val_path = \"data/MICCAI_long_tail_val.tfrecords\"\n",
    "val_index = \"data/MICCAI_long_tail_val.tfindex\"\n",
    "opt_lr = 1e-4\n",
    "weight_decay = 0\n",
    "training = True\n",
    "train_name = \"\"\n",
    "val_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aLyrClybsrF0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6577,
     "status": "ok",
     "timestamp": 1698593684914,
     "user": {
      "displayName": "申牧義",
      "userId": "07372378923452571676"
     },
     "user_tz": -480
    },
    "id": "aLyrClybsrF0",
    "outputId": "0ce4e2d7-9f6c-4583-caff-b8ca2cfddff8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "encoder = SSLEncoder(embDimension=num_classes).to(device)\n",
    "# encoder = torch.load('ssl_backbone2.pth')\n",
    "opt = optim.Adam(encoder.parameters(), lr=opt_lr, weight_decay = weight_decay)\n",
    "train_loader = Myloader(train_path, train_index, batch_size, num_workers=0, shuffle=True)\n",
    "val_loader = Myloader(val_path, val_index, batch_size, num_workers=0, shuffle=False)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hollywood-momentum",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hollywood-momentum",
    "outputId": "aabc8166-a3ad-4d16-eb1e-dcd71b9218dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: 1024/unknown finished / train loss: 0.43379271402955055\n",
      "epoch 0: 2048/unknown finished / train loss: 0.3772197151556611\n",
      "epoch 0: 3072/unknown finished / train loss: 0.3511858587153256\n",
      "epoch 0: 4096/unknown finished / train loss: 0.34119522280525416\n",
      "epoch 0: 5120/unknown finished / train loss: 0.33057605093345044\n",
      "epoch 0: 6144/unknown finished / train loss: 0.3251800717941175\n",
      "epoch 0: 7168/unknown finished / train loss: 0.32235857252297656\n",
      "epoch 0: 8192/unknown finished / train loss: 0.31886282440973446\n",
      "epoch 0: 9216/unknown finished / train loss: 0.3142536953609023\n",
      "epoch 0: 10240/unknown finished / train loss: 0.3121962255332619\n",
      "epoch 0: 11264/unknown finished / train loss: 0.3102788572961634\n",
      "epoch 0: 12288/unknown finished / train loss: 0.3091770372508715\n",
      "epoch 0: 13312/unknown finished / train loss: 0.3066760735729566\n",
      "epoch 0: 14336/unknown finished / train loss: 0.305360821940537\n",
      "epoch 0: 15360/unknown finished / train loss: 0.3046490643794338\n",
      "epoch 0: 16384/unknown finished / train loss: 0.3029266158991959\n",
      "epoch 0: 17408/unknown finished / train loss: 0.30175024577799964\n",
      "epoch 0: 18432/unknown finished / train loss: 0.3013867862884783\n",
      "epoch 0: 19456/unknown finished / train loss: 0.30038443462629066\n",
      "epoch 0: 20480/unknown finished / train loss: 0.299522545048967\n",
      "epoch 0: 21504/unknown finished / train loss: 0.2987553379054935\n",
      "epoch 0: 22528/unknown finished / train loss: 0.2982175591486422\n",
      "epoch 0: 23552/unknown finished / train loss: 0.2976562326328586\n",
      "epoch 0: 24576/unknown finished / train loss: 0.29698477955147\n",
      "epoch 0: 25600/unknown finished / train loss: 0.29663583531975746\n",
      "epoch 0: 26624/unknown finished / train loss: 0.29630013639465547\n",
      "epoch 0: 27648/unknown finished / train loss: 0.29582045725719247\n",
      "epoch 0: 28672/unknown finished / train loss: 0.29523101335923585\n",
      "epoch 0: 29696/unknown finished / train loss: 0.2949325793326415\n",
      "epoch 0: 30720/unknown finished / train loss: 0.2946726055971036\n",
      "epoch 0: 31744/unknown finished / train loss: 0.2942283248468753\n",
      "epoch 0: 32768/unknown finished / train loss: 0.29401490063173696\n",
      "epoch 0: 33792/unknown finished / train loss: 0.2938660859327876\n",
      "epoch 0: 34816/unknown finished / train loss: 0.2935876104816356\n",
      "epoch 0: 35840/unknown finished / train loss: 0.2935093004389533\n",
      "epoch 0: 36864/unknown finished / train loss: 0.29293476334876484\n",
      "epoch 0: 37888/unknown finished / train loss: 0.29314805751011985\n",
      "epoch 0: 38912/unknown finished / train loss: 0.293125224606085\n",
      "epoch 0: 39936/unknown finished / train loss: 0.29298586632387763\n",
      "epoch 0: 40960/unknown finished / train loss: 0.29283809929620475\n",
      "epoch 0: 41984/unknown finished / train loss: 0.29305614299345306\n",
      "epoch 0: 43008/unknown finished / train loss: 0.2927158391768379\n",
      "epoch 0: 44032/unknown finished / train loss: 0.29252772165332425\n",
      "epoch 0: 45056/unknown finished / train loss: 0.29254974805834616\n",
      "epoch 0: 46080/unknown finished / train loss: 0.29262053181106845\n",
      "epoch 0: 47104/unknown finished / train loss: 0.2923454277764034\n",
      "epoch 0: 48128/unknown finished / train loss: 0.29243650537063465\n",
      "epoch 0: 49152/unknown finished / train loss: 0.2922457814080796\n",
      "epoch 0: 50176/unknown finished / train loss: 0.2919748664111355\n",
      "epoch 0: 51200/unknown finished / train loss: 0.29200314151123163\n",
      "epoch 0: 52224/unknown finished / train loss: 0.29207502842387734\n",
      "epoch 0: 53248/unknown finished / train loss: 0.29166645599672425\n",
      "epoch 0: 54272/unknown finished / train loss: 0.29150725294009977\n",
      "epoch 0: 55296/unknown finished / train loss: 0.2912352570091133\n",
      "epoch 0: 56320/unknown finished / train loss: 0.29101455004208465\n",
      "epoch 0: 57344/unknown finished / train loss: 0.2906672055334119\n",
      "epoch 0: 58368/unknown finished / train loss: 0.2904761456557664\n",
      "epoch 0: 59392/unknown finished / train loss: 0.2902711616861152\n",
      "epoch 0: 60416/unknown finished / train loss: 0.2901248751539674\n",
      "epoch 0: 61440/unknown finished / train loss: 0.289814637399589\n",
      "epoch 0: 62464/unknown finished / train loss: 0.2898243639663961\n",
      "epoch 0: 63488/unknown finished / train loss: 0.28960215488088226\n",
      "epoch 0: 64512/unknown finished / train loss: 0.2894379670790855\n",
      "epoch 0: 65536/unknown finished / train loss: 0.28923317329463316\n",
      "epoch 0: 66560/unknown finished / train loss: 0.28921978978010326\n",
      "epoch 0: 67584/unknown finished / train loss: 0.28912311448066524\n",
      "epoch 0: 68608/unknown finished / train loss: 0.28905628972561725\n",
      "epoch 0: 69632/unknown finished / train loss: 0.2890074964379892\n",
      "epoch 0: 70656/unknown finished / train loss: 0.28883461189874704\n",
      "epoch 0: 71680/unknown finished / train loss: 0.2886595369449684\n",
      "epoch 0: 72704/unknown finished / train loss: 0.2883052875182893\n",
      "epoch 0: 73728/unknown finished / train loss: 0.2880919748179925\n",
      "epoch 0: 74752/unknown finished / train loss: 0.28797482628349774\n",
      "epoch 0: 75776/unknown finished / train loss: 0.28783338479194287\n",
      "epoch 0: 76800/unknown finished / train loss: 0.2875875143955151\n",
      "epoch 0: 77824/unknown finished / train loss: 0.2874748242381764\n",
      "epoch 0: 78848/unknown finished / train loss: 0.28731726688731996\n",
      "epoch 0: 79872/unknown finished / train loss: 0.28704417979893965\n",
      "epoch 0: 80896/unknown finished / train loss: 0.2869558007031962\n",
      "epoch 0: 81920/unknown finished / train loss: 0.2868173493130598\n",
      "epoch 0: 82944/unknown finished / train loss: 0.2867232458321033\n",
      "epoch 0: 83968/unknown finished / train loss: 0.28656962529824276\n",
      "epoch 0: 84992/unknown finished / train loss: 0.2865705729563193\n",
      "epoch 0: 86016/unknown finished / train loss: 0.286415281910671\n",
      "epoch 0: 87040/unknown finished / train loss: 0.28647801046643184\n",
      "epoch 0: 88064/unknown finished / train loss: 0.28629184354551485\n",
      "epoch 0: 89088/unknown finished / train loss: 0.28616363304164044\n",
      "epoch 0: 90112/unknown finished / train loss: 0.28603381620698864\n",
      "epoch 0: 91136/unknown finished / train loss: 0.28592697686379714\n",
      "epoch 0: 92160/unknown finished / train loss: 0.28594528316623635\n",
      "epoch 0: 93184/unknown finished / train loss: 0.2858255918260541\n",
      "epoch 0: 94208/unknown finished / train loss: 0.2855993956681746\n",
      "epoch 0: 95232/unknown finished / train loss: 0.2855439860303636\n",
      "epoch 0: 96256/unknown finished / train loss: 0.2853722825468062\n",
      "epoch 0: 97280/unknown finished / train loss: 0.28535704584302085\n",
      "epoch 0: 98304/unknown finished / train loss: 0.2851553774429097\n",
      "epoch 0: 99328/unknown finished / train loss: 0.2852256857722844\n",
      "epoch 0: 100352/unknown finished / train loss: 0.2851379517399307\n",
      "epoch 0: 101376/unknown finished / train loss: 0.2849367688917978\n",
      "epoch 0: 102400/unknown finished / train loss: 0.2847709064837545\n",
      "epoch 0: 103424/unknown finished / train loss: 0.2846505583014966\n",
      "epoch 0: 104448/unknown finished / train loss: 0.284539230469176\n",
      "epoch 0: 105472/unknown finished / train loss: 0.2844675693308338\n",
      "epoch 0: 106496/unknown finished / train loss: 0.2844829586236021\n",
      "epoch 0: 107520/unknown finished / train loss: 0.2845292595392537\n",
      "epoch 0: 108544/unknown finished / train loss: 0.2844180045341897\n",
      "epoch 0: 109568/unknown finished / train loss: 0.28440345124837674\n",
      "epoch 0: 110592/unknown finished / train loss: 0.28431250592607454\n",
      "epoch 0: 111616/unknown finished / train loss: 0.2843223281734444\n",
      "epoch 0: 112640/unknown finished / train loss: 0.2843774718274786\n",
      "epoch 0: 113664/unknown finished / train loss: 0.2842792251130549\n",
      "epoch 0: 114688/unknown finished / train loss: 0.28423681221153985\n",
      "epoch 0: 115712/unknown finished / train loss: 0.28413899680105065\n",
      "epoch 0: 116736/unknown finished / train loss: 0.28401672254774\n",
      "epoch 0: 117760/unknown finished / train loss: 0.284011180953973\n",
      "epoch 0: 118784/unknown finished / train loss: 0.28397488989064407\n",
      "epoch 0: 119808/unknown finished / train loss: 0.2839186011861341\n",
      "epoch 0: 120832/unknown finished / train loss: 0.2838522621698804\n",
      "epoch 0: 121856/unknown finished / train loss: 0.2839280245747386\n",
      "epoch 0: 122880/unknown finished / train loss: 0.2839404635868656\n",
      "epoch 0: 123904/unknown finished / train loss: 0.283920686784362\n",
      "epoch 0: 124928/unknown finished / train loss: 0.2838285323346919\n",
      "epoch 0: 125952/unknown finished / train loss: 0.2838045752425564\n",
      "epoch 0: 126976/unknown finished / train loss: 0.28371642037640293\n",
      "epoch 0: 128000/unknown finished / train loss: 0.28363072569295766\n",
      "epoch 0: 129024/unknown finished / train loss: 0.28349715698924327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: 130048/unknown finished / train loss: 0.2833803307455708\n",
      "epoch 0: 131072/unknown finished / train loss: 0.28338045490454533\n",
      "epoch 0: 132096/unknown finished / train loss: 0.28325368595027994\n",
      "epoch 0: 133120/unknown finished / train loss: 0.2831935370591684\n",
      "epoch 0: 134144/unknown finished / train loss: 0.2831644705063059\n",
      "epoch 0: 135168/unknown finished / train loss: 0.2830942333005651\n",
      "epoch 0: 136192/unknown finished / train loss: 0.28300263613280385\n",
      "epoch 0: 137216/unknown finished / train loss: 0.28297923746129583\n",
      "epoch 0: 138240/unknown finished / train loss: 0.2829371162345288\n",
      "epoch 0: 139264/unknown finished / train loss: 0.2828768755459939\n",
      "epoch 0: 140288/unknown finished / train loss: 0.2828370246995431\n",
      "epoch 0: 141312/unknown finished / train loss: 0.2827835835624432\n",
      "epoch 0: 142336/unknown finished / train loss: 0.2826921896030791\n",
      "epoch 0: 143360/unknown finished / train loss: 0.282563417907139\n",
      "epoch 0: 144384/unknown finished / train loss: 0.28258217886380904\n",
      "epoch 0: 145408/unknown finished / train loss: 0.2824928245218602\n",
      "epoch 0: 146432/unknown finished / train loss: 0.2825259139038414\n",
      "epoch 0: 147456/unknown finished / train loss: 0.2824543078669295\n",
      "epoch 0: 148480/unknown finished / train loss: 0.2823836304889671\n",
      "epoch 0: 149504/unknown finished / train loss: 0.28238018512508944\n",
      "epoch 0: 150528/unknown finished / train loss: 0.2823519804673333\n",
      "epoch 0: 151552/unknown finished / train loss: 0.2822763961739838\n",
      "epoch 0: 152576/unknown finished / train loss: 0.2822307521733612\n",
      "epoch 0: 153600/unknown finished / train loss: 0.2822838408996661\n",
      "epoch 0: 154624/unknown finished / train loss: 0.2822366762776791\n",
      "epoch 0: 155648/unknown finished / train loss: 0.2821961354991225\n",
      "epoch 0: 156672/unknown finished / train loss: 0.28214134001994834\n",
      "epoch 0: 157696/unknown finished / train loss: 0.2821255672583961\n",
      "epoch 0: 158720/unknown finished / train loss: 0.2820980610265847\n",
      "epoch 0: 159744/unknown finished / train loss: 0.28202238564307874\n",
      "epoch 0: 160768/unknown finished / train loss: 0.28199165958650174\n",
      "epoch 0: 161792/unknown finished / train loss: 0.2819114185345088\n",
      "epoch 0: 162816/unknown finished / train loss: 0.28183430111703445\n",
      "epoch 0: 163840/unknown finished / train loss: 0.2817945340328151\n",
      "epoch 0: 164864/unknown finished / train loss: 0.28176459334270093\n",
      "epoch 0: 165888/unknown finished / train loss: 0.281772007027434\n",
      "epoch 0: 166912/unknown finished / train loss: 0.28169409601600626\n",
      "epoch 0: 167936/unknown finished / train loss: 0.28160027829964257\n",
      "epoch 0: 168960/unknown finished / train loss: 0.2815652863291854\n",
      "epoch 0: 169984/unknown finished / train loss: 0.28142501576242585\n",
      "epoch 0: 171008/unknown finished / train loss: 0.2813299491298859\n",
      "epoch 0: 172032/unknown finished / train loss: 0.281269542426647\n",
      "epoch 0: 173056/unknown finished / train loss: 0.28124343996492807\n",
      "epoch 0: 174080/unknown finished / train loss: 0.28112872012288254\n",
      "epoch 0: 175104/unknown finished / train loss: 0.2810454429671909\n",
      "epoch 0: 176128/unknown finished / train loss: 0.2809625087051414\n",
      "epoch 0: 177152/unknown finished / train loss: 0.2809483272432635\n",
      "epoch 0: 178176/unknown finished / train loss: 0.28088991306240446\n",
      "epoch 0: 179200/unknown finished / train loss: 0.2808711711051209\n",
      "epoch 0: 180224/unknown finished / train loss: 0.2808260175013195\n",
      "epoch 0: 181248/unknown finished / train loss: 0.2807845931268681\n",
      "epoch 0: 182272/unknown finished / train loss: 0.2806862686012526\n",
      "epoch 0 / mAP: 0.13878397643566132 / test loss: 0.8970932535666145 / duration: 2891.946916818619\n",
      "epoch 1: 160/182380 (0.00 %) finished / train loss: 0.2973436713218689\n",
      "epoch 1: 320/182380 (0.00 %) finished / train loss: 0.28384949862957\n",
      "epoch 1: 480/182380 (0.00 %) finished / train loss: 0.27586202720801034\n",
      "epoch 1: 640/182380 (0.00 %) finished / train loss: 0.2708596892654896\n",
      "epoch 1: 800/182380 (0.00 %) finished / train loss: 0.2685544788837433\n",
      "epoch 1: 960/182380 (0.01 %) finished / train loss: 0.2642619659503301\n",
      "epoch 1: 1120/182380 (0.01 %) finished / train loss: 0.2652416054691587\n",
      "epoch 1: 1280/182380 (0.01 %) finished / train loss: 0.26593800708651544\n",
      "epoch 1: 1440/182380 (0.01 %) finished / train loss: 0.2641383740637038\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, labels)\n\u001b[0;32m     34\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 35\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m     38\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m imgs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:370\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 370\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_opt_step(optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    372\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:289\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    288\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    290\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:289\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    288\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    290\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "if training == True:\n",
    "#         wandb.init(\n",
    "#             project='chexpert mitigate bias',\n",
    "#             name= train_wandb_name)\n",
    "#         config = wandb.config\n",
    "#         config.batch_size = batch_size\n",
    "    max_map = 0\n",
    "    total = 0\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        encoder.train()\n",
    "        running_loss = 0.0\n",
    "        start_time = time.time()\n",
    "        count = 0\n",
    "\n",
    "        for (imgs, labels, dicom_ids) in train_loader:\n",
    "            encoder.zero_grad()\n",
    "            opt.zero_grad()\n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.squeeze(-1)\n",
    "\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                output = encoder(imgs)\n",
    "                # print('check')\n",
    "                # print(output)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            count += imgs.size(0)\n",
    "\n",
    "            if count != 0 and count % 1024 == 0 and total == 0:\n",
    "                print(f\"epoch {epoch}: {count}/unknown finished / train loss: {running_loss / count}\")\n",
    "\n",
    "            elif count != 0 and count % 10 == 0 and total != 0:\n",
    "                print(f\"epoch {epoch}: {count}/{total} (%.2f %%) finished / train loss: {running_loss / count}\" % (count/total))\n",
    "\n",
    "        total = count\n",
    "        mAP, test_running_loss, test_total = evaluate(encoder, val_loader)\n",
    "        \n",
    "        train_losses.append(running_loss / count)\n",
    "        test_losses.append(test_running_loss)\n",
    "        \n",
    "        if mAP > max_map:\n",
    "            max_map = mAP\n",
    "            torch.save({\n",
    "                'model_state_dict': encoder.state_dict(),\n",
    "                'optimizer_state_dict': opt.state_dict(),\n",
    "            }, f\"{weight_path}/ssl_model_best.pt\")\n",
    "        if epoch % 10 == 0:\n",
    "            torch.save({\n",
    "                    'model_state_dict': encoder.state_dict(),\n",
    "                    'optimizer_state_dict': opt.state_dict(),\n",
    "                }, weight_path+\"/{}epoch_ssl.pt\".format(epoch))\n",
    "\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "\n",
    "        print(f\"epoch {epoch} / mAP: {mAP} / test loss: {test_running_loss / test_total} / duration: {duration}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d8069f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
